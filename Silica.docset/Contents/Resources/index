#!/usr/bin/env python3
import bs4, os, re, sqlite3, time, urllib.request
def soup_from_url(url):
    print("Parsing {}".format(url))
    page = urllib.request.urlopen(url).read()
    return bs4.BeautifulSoup(page, "html.parser")
def get_hrefs(soup, pattern):
    return soup.find_all("a", {"href": re.compile(pattern)})
os.chdir(os.path.dirname(os.path.abspath(__file__)))
if os.path.isfile("docSet.dsidx"):
    os.remove("docSet.dsidx")
db = sqlite3.connect("docSet.dsidx")
cursor = db.cursor()
cursor.execute("CREATE TABLE searchIndex(id INTEGER PRIMARY KEY, name TEXT, type TEXT, path TEXT);")
cursor.execute("CREATE UNIQUE INDEX anchor ON searchIndex (name, type, path);")
soup = soup_from_url("https://sailfishos.org/develop/docs/silica/sailfish-silica-all.html")
root = "https://sailfishos.org/develop/docs/silica/"
sql = "INSERT OR IGNORE INTO searchIndex(name, type, path) VALUES (?,?,?)"
added = []
for tag in get_hrefs(soup, "qml-.*html"):
    name = tag.text.strip()
    path = root + tag.attrs["href"].strip()
    if not (name, path) in added:
        print("{}: {}".format(name, path))
        cursor.execute(sql, (name, "func", path))
        added.append((name, path))
    soup = soup_from_url(path)
    for tag in get_hrefs(soup, "-(prop|method)$"):
        fullname = ".".join((name, tag.text.strip()))
        fullpath = root + tag.attrs["href"].strip()
        if not fullpath.startswith(path): continue
        if not ((fullname, fullpath)) in added:
            print("{}: {}".format(fullname, fullpath))
            cursor.execute(sql, (fullname, "func", fullpath))
            added.append((fullname, fullpath))
    time.sleep(1)
db.commit()
db.close()
